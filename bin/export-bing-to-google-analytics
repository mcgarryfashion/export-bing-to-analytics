#!/usr/bin/env python
import newrelic.agent
newrelic.agent.initialize()

from bingads import *

import time
import contextlib
import ssl
import requests
import zipfile
import os
import six
import sys

from requests.adapters import HTTPAdapter
from requests.packages.urllib3.poolmanager import PoolManager

import webbrowser
from time import gmtime, strftime

from apiclient.discovery import build
from oauth2client.client import SignedJwtAssertionCredentials
from oauth2client.client import OAuth2WebServerFlow

# Optionally you can include logging to output traffic, for example the SOAP request and response.

import logging
logging.basicConfig(level=logging.WARNING)
logging.getLogger('suds.client').setLevel(logging.WARNING)

import csv
import datetime

from apiclient.discovery import build
from apiclient.http import MediaFileUpload
import httplib2
from oauth2client import client
from oauth2client import file
from oauth2client import tools
import argparse

# constants that may need adjusting

# these two are storage for credentials
# you should not need to change them providing
# providing the program is run from the same
# directory everything is stored in
credential_storage = 'analytics.dat'
bing_refresh_token = 'refresh.txt'

# A directory to store the report files
# Must end in trailing /
FILE_DIRECTORY='tmp/'

# Credentials read from Environment Variables
DEVELOPER_TOKEN=os.environ['DEVELOPER_TOKEN']
CLIENT_ID=os.environ['CLIENT_ID']

GOOGLE_CLIENT_ID=os.environ['GOOGLE_CLIENT_ID']
GOOGLE_CLIENT_SECRET=os.environ['GOOGLE_CLIENT_SECRET']
GOOGLE_ACCESS_TOKEN=os.environ['GOOGLE_ACCESS_TOKEN']
GOOGLE_REFRESH_TOKEN=os.environ['GOOGLE_REFRESH_TOKEN']

# This writes out the analytics credentials - in time eliminate this and do server to server oauth properly!
analytics_credentials = { "_module": "oauth2client.client", "scopes": ["https://www.googleapis.com/auth/analytics"], "token_expiry": "2015-10-27T22:04:36Z", "id_token": None, "access_token": GOOGLE_ACCESS_TOKEN, "token_uri": "https://accounts.google.com/o/oauth2/token", "invalid": False, "token_response": { "access_token": GOOGLE_ACCESS_TOKEN, "token_type": "Bearer", "expires_in": 3600 }, "client_id": GOOGLE_CLIENT_ID, "token_info_uri": "https://www.googleapis.com/oauth2/v2/tokeninfo", "client_secret": GOOGLE_CLIENT_SECRET, "revoke_uri": "https://accounts.google.com/o/oauth2/revoke", "_class": "OAuth2Credentials", "refresh_token": GOOGLE_REFRESH_TOKEN, "user_agent": None }
import json
with open(credential_storage, 'w') as outfile:
    json.dump(analytics_credentials, outfile)

UK_BING_ID=os.environ['UK_BING_ID']
UK_DATA_SOURCE_ID=os.environ['UK_DATA_SOURCE_ID']
UK_ACCOUNT_ID=os.environ['UK_ACCOUNT_ID']
UK_PROPERTY_ID=os.environ['UK_PROPERTY_ID']

USA_BING_ID=os.environ['USA_BING_ID']
USA_DATA_SOURCE_ID=os.environ['USA_DATA_SOURCE_ID']
USA_ACCOUNT_ID=os.environ['USA_ACCOUNT_ID']
USA_PROPERTY_ID=os.environ['USA_PROPERTY_ID']

SWEDEN_BING_ID=os.environ['SWEDEN_BING_ID']
SWEDEN_DATA_SOURCE_ID=os.environ['SWEDEN_DATA_SOURCE_ID']
SWEDEN_ACCOUNT_ID=os.environ['SWEDEN_ACCOUNT_ID']
SWEDEN_PROPERTY_ID=os.environ['SWEDEN_PROPERTY_ID']

SPAIN_BING_ID=os.environ['SPAIN_BING_ID']
SPAIN_DATA_SOURCE_ID=os.environ['SPAIN_DATA_SOURCE_ID']
SPAIN_ACCOUNT_ID=os.environ['SPAIN_ACCOUNT_ID']
SPAIN_PROPERTY_ID=os.environ['SPAIN_PROPERTY_ID']

ITALY_BING_ID=os.environ['ITALY_BING_ID']
ITALY_DATA_SOURCE_ID=os.environ['ITALY_DATA_SOURCE_ID']
ITALY_ACCOUNT_ID=os.environ['ITALY_ACCOUNT_ID']
ITALY_PROPERTY_ID=os.environ['ITALY_PROPERTY_ID']

PORTUGAL_BING_ID=os.environ['PORTUGAL_BING_ID']
PORTUGAL_DATA_SOURCE_ID=os.environ['PORTUGAL_DATA_SOURCE_ID']
PORTUGAL_ACCOUNT_ID=os.environ['PORTUGAL_ACCOUNT_ID']
PORTUGAL_PROPERTY_ID=os.environ['PORTUGAL_PROPERTY_ID']

# Contains information on the accounts to
# run this over
account_source_pairs = [
        {'bingid': UK_BING_ID,
         'datasourceid': UK_DATA_SOURCE_ID,
         'country': 'UK',
         'accountid': UK_ACCOUNT_ID,
         'propertyid': UK_PROPERTY_ID
        },
        {'bingid': USA_BING_ID,
         'datasourceid': USA_DATA_SOURCE_ID,
         'country': 'USA',
         'accountid': USA_ACCOUNT_ID,
         'propertyid': USA_PROPERTY_ID
         },
        {'bingid': SWEDEN_BING_ID,
         'datasourceid': SWEDEN_DATA_SOURCE_ID,
         'country': 'Sweden',
         'accountid': SWEDEN_ACCOUNT_ID,
         'propertyid': SWEDEN_PROPERTY_ID
         },
        {'bingid': SPAIN_BING_ID,
         'datasourceid': SPAIN_DATA_SOURCE_ID,
         'country': 'Spain',
         'accountid': SPAIN_ACCOUNT_ID,
         'propertyid': SPAIN_PROPERTY_ID
         },
        {'bingid': ITALY_BING_ID,
         'datasourceid': ITALY_DATA_SOURCE_ID,
         'country': 'Italy',
         'accountid' : ITALY_ACCOUNT_ID,
         'propertyid': ITALY_PROPERTY_ID
        },
        {'bingid': PORTUGAL_BING_ID,
         'datasourceid': PORTUGAL_DATA_SOURCE_ID,
         'country': 'Portugal',
         'accountid': PORTUGAL_ACCOUNT_ID,
         'propertyid': PORTUGAL_PROPERTY_ID
        }
    ]

# no more configuration. Edit anything below here at your peril

# convert a date from Bing format to Google format
def formatDate(d):
    datesegments = d.split("/")
    dt = datetime.date(int(datesegments[2]), int(datesegments[0]), int(datesegments[1]))
    return(dt.strftime("%Y%m%d"))

# convert a Bing report into the format for Google upload
def convertFile(infile,outfile):
    with open(infile, 'rb') as csvin:
      with open(outfile,'wb') as csvout:
        for _ in xrange(11):
          next(csvin)
        csvreader = csv.reader(csvin, delimiter=',', quotechar='"')
        csvwriter = csv.writer(csvout)
        headerrow = ["ga:date","ga:medium","ga:source","ga:adCost","ga:adClicks","ga:impressions","ga:campaign","ga:keyword"]
        csvwriter.writerow(headerrow)
        for row in csvreader:
          if (len(row) == 6):
            necessarycells = [formatDate(row[0]),
                          'cpc',
                          'bingads',
                          float(row[1]),
                          int(row[2]),
                          int(row[3]),
                          row[4],
                          row[5]
                          ]
            csvwriter.writerow(necessarycells)

scope = ['https://www.googleapis.com/auth/analytics']

if __name__ == '__main__':
    print("Python loads the web service proxies at runtime, so you will observe " \
          "a performance delay between program launch and main execution...\n")

    ENVIRONMENT='production'


    authorization_data=AuthorizationData(
        account_id=None,
        customer_id=None,
        developer_token=DEVELOPER_TOKEN,
        authentication=None,
    )

    customer_service=ServiceClient(
        'CustomerManagementService', 
        authorization_data=authorization_data, 
        environment=ENVIRONMENT,
    )

    reporting_service=ServiceClient(
        'ReportingService', 
        authorization_data=authorization_data, 
        environment=ENVIRONMENT,
    )

class Ssl3HttpAdapter(HTTPAdapter):
    """" Transport adapter" that allows us to use SSLv3. """

    def init_poolmanager(self, connections, maxsize, block=False):
        self.poolmanager=PoolManager(
            num_pools=connections,
            maxsize=maxsize,
            block=block,
            ssl_version=ssl.PROTOCOL_SSLv3,
        )

def authenticate_with_username():
    ''' 
    Sets the authentication property of the global AuthorizationData instance with PasswordAuthentication.
    '''
    global authorization_data
    authentication=PasswordAuthentication(
        user_name='UserNameGoesHere',
        password='PasswordGoesHere'
    )

    # Assign this authentication instance to the global authorization_data. 
    authorization_data.authentication=authentication

def authenticate_with_oauth():
    ''' 
    Sets the authentication property of the global AuthorizationData instance with OAuthDesktopMobileAuthCodeGrant.
    '''
    global authorization_data
    authentication=OAuthDesktopMobileAuthCodeGrant(
        client_id=CLIENT_ID
    )

    # Assign this authentication instance to the global authorization_data. 
    authorization_data.authentication=authentication   

    # Register the callback function to automatically save the refresh token anytime it is refreshed.
    # Uncomment this line if you want to store your refresh token. Be sure to save your refresh token securely.
    authorization_data.authentication.token_refreshed_callback=save_refresh_token

    refresh_token=get_refresh_token()
 
    # If we have a refresh token let's refresh it
    if refresh_token is not None:
        authentication.request_oauth_tokens_by_refresh_token(refresh_token)
    else:
        webbrowser.open(authentication.get_authorization_endpoint(), new=1)
        # For Python 3.x use 'input' instead of 'raw_input'
        if(sys.version_info.major >= 3):
            response_uri=input(
                "You need to provide consent for the application to access your Bing Ads accounts. " \
                "After you have granted consent in the web browser for the application to access your Bing Ads accounts, " \
                "please enter the response URI that includes the authorization 'code' parameter: \n"
            )
        else:
            response_uri=raw_input(
                "You need to provide consent for the application to access your Bing Ads accounts. " \
                "After you have granted consent in the web browser for the application to access your Bing Ads accounts, " \
                "please enter the response URI that includes the authorization 'code' parameter: \n"
            )

        # Request access and refresh tokens using the URI that you provided manually during program execution.
        authentication.request_oauth_tokens_by_response_uri(response_uri=response_uri) 

def get_refresh_token():
    ''' 
    Returns a refresh token if stored locally.
    '''
    file=None
    try:
        file=open(bing_refresh_token)
        line=file.readline()
        file.close()
        return line if line else None
    except IOError:
        if file:
            file.close()
        return os.environ['BING_REFRESH_TOKEN']

def save_refresh_token(oauth_tokens):
    ''' 
    Stores a refresh token locally. Be sure to save your refresh token securely.
    '''
    with open("refresh.txt","w+") as file:
        file.write(oauth_tokens.refresh_token)
        file.close()
    return None

def search_accounts_by_user_id(user_id):
    '''
    Search for account details by UserId.
    
    :param user_id: The Bing Ads user identifier.
    :type user_id: long
    :return: List of accounts that the user can manage.
    :rtype: ArrayOfAccount
    '''
    global customer_service

    paging={
        'Index': 0,
        'Size': 10
    }

    predicates={
        'Predicate': [
            {
                'Field': 'UserId',
                'Operator': 'Equals',
                'Value': user_id,
            },
        ]
    }

    search_accounts_request={
        'PageInfo': paging,
        'Predicates': predicates
    }
        
    return customer_service.SearchAccounts(
        PageInfo = paging,
        Predicates = predicates
    )

def output_status_message(message):
    print(message)

def output_bing_ads_webfault_error(error):
    if hasattr(error, 'ErrorCode'):
        output_status_message("ErrorCode: {0}".format(error.ErrorCode))
    if hasattr(error, 'Code'):
        output_status_message("Code: {0}".format(error.Code))
    if hasattr(error, 'Message'):
        output_status_message("Message: {0}".format(error.Message))
    output_status_message('')

def output_webfault_errors(ex):
    if hasattr(ex.fault, 'detail') \
        and hasattr(ex.fault.detail, 'ApiFault') \
        and hasattr(ex.fault.detail.ApiFault, 'OperationErrors') \
        and hasattr(ex.fault.detail.ApiFault.OperationErrors, 'OperationError'):
        api_errors=ex.fault.detail.ApiFault.OperationErrors.OperationError
        if type(api_errors) == list:
            for api_error in api_errors:
                output_bing_ads_webfault_error(api_error)
        else:
            output_bing_ads_webfault_error(api_errors)
    elif hasattr(ex.fault, 'detail') \
        and hasattr(ex.fault.detail, 'AdApiFaultDetail') \
        and hasattr(ex.fault.detail.AdApiFaultDetail, 'Errors') \
        and hasattr(ex.fault.detail.AdApiFaultDetail.Errors, 'AdApiError'):
        api_errors=ex.fault.detail.AdApiFaultDetail.Errors.AdApiError
        if type(api_errors) == list:
            for api_error in api_errors:
                output_bing_ads_webfault_error(api_error)
        else:
            output_bing_ads_webfault_error(api_errors)
    elif hasattr(ex.fault, 'detail') \
        and hasattr(ex.fault.detail, 'ApiFaultDetail') \
        and hasattr(ex.fault.detail.ApiFaultDetail, 'BatchErrors') \
        and hasattr(ex.fault.detail.ApiFaultDetail.BatchErrors, 'BatchError'):
        api_errors=ex.fault.detail.ApiFaultDetail.BatchErrors.BatchError
        if type(api_errors) == list:
            for api_error in api_errors:
                output_bing_ads_webfault_error(api_error)
        else:
            output_bing_ads_webfault_error(api_errors)
    elif hasattr(ex.fault, 'detail') \
        and hasattr(ex.fault.detail, 'ApiFaultDetail') \
        and hasattr(ex.fault.detail.ApiFaultDetail, 'OperationErrors') \
        and hasattr(ex.fault.detail.ApiFaultDetail.OperationErrors, 'OperationError'):
        api_errors=ex.fault.detail.ApiFaultDetail.OperationErrors.OperationError
        if type(api_errors) == list:
            for api_error in api_errors:
                output_bing_ads_webfault_error(api_error)
        else:
            output_bing_ads_webfault_error(api_errors)
    elif hasattr(ex.fault, 'detail') \
        and hasattr(ex.fault.detail, 'EditorialApiFaultDetail') \
        and hasattr(ex.fault.detail.EditorialApiFaultDetail, 'BatchErrors') \
        and hasattr(ex.fault.detail.EditorialApiFaultDetail.BatchErrors, 'BatchError'):
        api_errors=ex.fault.detail.EditorialApiFaultDetail.BatchErrors.BatchError
        if type(api_errors) == list:
            for api_error in api_errors:
                output_bing_ads_webfault_error(api_error)
        else:
            output_bing_ads_webfault_error(api_errors)
    elif hasattr(ex.fault, 'detail') \
        and hasattr(ex.fault.detail, 'EditorialApiFaultDetail') \
        and hasattr(ex.fault.detail.EditorialApiFaultDetail, 'EditorialErrors') \
        and hasattr(ex.fault.detail.EditorialApiFaultDetail.EditorialErrors, 'EditorialError'):
        api_errors=ex.fault.detail.EditorialApiFaultDetail.EditorialErrors.EditorialError
        if type(api_errors) == list:
            for api_error in api_errors:
                output_bing_ads_webfault_error(api_error)
        else:
            output_bing_ads_webfault_error(api_errors)
    elif hasattr(ex.fault, 'detail') \
        and hasattr(ex.fault.detail, 'EditorialApiFaultDetail') \
        and hasattr(ex.fault.detail.EditorialApiFaultDetail, 'OperationErrors') \
        and hasattr(ex.fault.detail.EditorialApiFaultDetail.OperationErrors, 'OperationError'):
        api_errors=ex.fault.detail.EditorialApiFaultDetail.OperationErrors.OperationError
        if type(api_errors) == list:
            for api_error in api_errors:
                output_bing_ads_webfault_error(api_error)
        else:
            output_bing_ads_webfault_error(api_errors)
    # Handle serialization errors e.g. The formatter threw an exception while trying to deserialize the message: 
    # There was an error while trying to deserialize parameter https://bingads.microsoft.com/CampaignManagement/v9:Entities.
    elif hasattr(ex.fault, 'detail') \
        and hasattr(ex.fault.detail, 'ExceptionDetail'):
        api_errors=ex.fault.detail.ExceptionDetail
        if type(api_errors) == list:
            for api_error in api_errors:
                output_status_message(api_error.Message)
        else:
            output_status_message(api_errors.Message)
    else:
        raise Exception('Unknown WebFault')

def download_result_file(url, result_file_directory, result_file_name, decompress, overwrite):
    """ Download file with specified URL and download parameters.

    :param result_file_directory: The download result local directory name.
    :type result_file_directory: str
    :param result_file_name: The download result local file name.
    :type result_file_name: str
    :param decompress: Determines whether to decompress the ZIP file.
                        If set to true, the file will be decompressed after download.
                        The default value is false, in which case the downloaded file is not decompressed.
    :type decompress: bool
    :param overwrite: Indicates whether the result file should overwrite the existing file if any.
    :type overwrite: bool
    :return: The download file path.
    :rtype: str
    """

    if result_file_directory is None:
        raise ValueError('result_file_directory cannot be None.')

    if result_file_name is None:
        result_file_name="default_file_name"

    if decompress:
        name, ext=os.path.splitext(result_file_name)
        if ext == '.zip':
            raise ValueError("Result file can't be decompressed into a file with extension 'zip'."
                                " Please change the extension of the result_file_name or pass decompress=false")
        zip_file_path=os.path.join(result_file_directory, name + '.zip')
        result_file_path=os.path.join(result_file_directory, result_file_name)
    else:
        result_file_path=os.path.join(result_file_directory, result_file_name)
        zip_file_path=result_file_path

    if os.path.exists(result_file_path) and overwrite is False:
        if six.PY3:
            raise FileExistsError('Result file: {0} exists'.format(result_file_path))
        else:
            raise OSError('Result file: {0} exists'.format(result_file_path))
    
    pool_manager=PoolManager(
        ssl_version=ssl.PROTOCOL_SSLv3,
    )
    http_adapter=HTTPAdapter()
    http_adapter.poolmanager=pool_manager
    
    s=requests.Session()
    s.mount('https://', http_adapter)
    r=s.get(url, stream=True, verify=True)
    r.raise_for_status()
    try:
        with open(zip_file_path, 'wb') as f:
            for chunk in r.iter_content(chunk_size=4096):
                if chunk:
                    f.write(chunk)
                    f.flush()
        if decompress:
            with contextlib.closing(zipfile.ZipFile(zip_file_path)) as compressed:
                first=compressed.namelist()[0]
                with open(result_file_path, 'wb') as f:
                    f.write(compressed.read(first))
    except Exception as ex:
        raise ex
    finally:
        if decompress and os.path.exists(zip_file_path):
            os.remove(zip_file_path)
    return result_file_path

def get_keyword_report_request():
    '''
    Build a keyword performance report request, including Format, ReportName, Aggregation,
    Scope, Time, Filter, and Columns.
    '''
    report_request=reporting_service.factory.create('KeywordPerformanceReportRequest')
    report_request.Format='Csv'
    report_request.ReportName='My Keyword Performance Report'
    report_request.ReturnOnlyCompleteData=False
    report_request.Aggregation='Daily'
    report_request.Language='English'

    scope=reporting_service.factory.create('AccountThroughAdGroupReportScope')
    scope.AccountIds={'long': [authorization_data.account_id] }
    scope.Campaigns=None
    scope.AdGroups=None
    report_request.Scope=scope

    report_time=reporting_service.factory.create('ReportTime')
    # You may either use a custom date range or predefined time.
    '''
    custom_date_range_start=reporting_service.factory.create('Date')
    custom_date_range_start.Day=1
    custom_date_range_start.Month=1
    custom_date_range_start.Year=2015
    report_time.CustomDateRangeStart=custom_date_range_start
    custom_date_range_end=reporting_service.factory.create('Date')
    custom_date_range_end.Day=28
    custom_date_range_end.Month=2
    custom_date_range_end.Year=2015
    report_time.CustomDateRangeEnd=custom_date_range_end
    report_time.PredefinedTime=None
    '''
    report_time.PredefinedTime='Yesterday'
    report_request.Time=report_time

    # If you specify a filter, results may differ from data you see in the Bing Ads web application
    """
    report_filter=reporting_service.factory.create('KeywordPerformanceReportFilter')
    report_filter.DeviceType=[
        'Computer',
        'SmartPhone'
    ]
    report_request.Filter=report_filter
    """
    # Specify the attribute and data report columns.

    report_columns=reporting_service.factory.create('ArrayOfKeywordPerformanceReportColumn')
    report_columns.KeywordPerformanceReportColumn.append([
        'TimePeriod',
        'Spend',
        'Clicks',
        'Impressions',
        'CampaignName',
        'Keyword'
    ])
    report_request.Columns=report_columns

    # You may optionally sort by any KeywordPerformanceReportColumn, and optionally
    # specify the maximum number of rows to return in the sorted report. 

    report_sorts=reporting_service.factory.create('ArrayOfKeywordPerformanceReportSort')
    report_sort=reporting_service.factory.create('KeywordPerformanceReportSort')
    report_sort.SortColumn='Clicks'
    report_sort.SortOrder='Ascending'
    report_sorts.KeywordPerformanceReportSort.append(report_sort)
    report_request.Sort=report_sorts

    return report_request

# Main execution
if __name__ == '__main__':

    try:
        # You should authenticate for Bing Ads production services with a Microsoft Account, 
        # instead of providing the Bing Ads username and password set. 
        # Authentication with a Microsoft Account is currently not supported in Sandbox.
        authenticate_with_oauth()

        # Uncomment to run with Bing Ads legacy UserName and Password credentials.
        # For example you would use this method to authenticate in sandbox.
        #authenticate_with_username()
        
        # Set to an empty user identifier to get the current authenticated Bing Ads user,
        # and then search for all accounts the user may access.
        for country in account_source_pairs:
          print country['country']
          user=customer_service.GetUser(None).User
          accounts=search_accounts_by_user_id(user.Id)

          account = next((x for x in accounts['Account'] if x['Number'] == country['bingid']), None )

          authorization_data.account_id=account.Id
          # Is it always the first account that has ParentCustomerId?
          authorization_data.customer_id=accounts['Account'][0].ParentCustomerId
        
          # Choose a helper method to build the report request, including Format, ReportName, Aggregation,
          # Scope, Time, Filter, and Columns.

          report_request=get_keyword_report_request()
        
          # SubmitGenerateReport returns the report identifier. The identifier is used to check report generation status
          # before downloading the report. 

          report_request_id=reporting_service.SubmitGenerateReport(
            ReportRequest=report_request,
          )
          result_file_name=country['bingid']+'.csv'
          report_request_status=None

          # This example polls every 5 seconds up to 2 minutes.
          # In production you may poll the status every 1 to 2 minutes for up to one hour.
          # If the call succeeds, stop polling. If the call or 
          # download fails, the call throws a fault.

          for _ in range(24):
            time.sleep(5)
            report_request_status=reporting_service.PollGenerateReport(
                ReportRequestId=report_request_id
            )
            if report_request_status.Status == 'Success':
                output_status_message("Downloading from {0}.".format(report_request_status.ReportDownloadUrl))
                download_result_file(
                    url=report_request_status.ReportDownloadUrl,
                    result_file_directory=FILE_DIRECTORY,
                    result_file_name=result_file_name,
                    decompress=True,
                    overwrite=True,
                )
                output_status_message("The report was written to {0}{1}.".format(FILE_DIRECTORY, result_file_name))
                convertFile(FILE_DIRECTORY+country['bingid']+'.csv',FILE_DIRECTORY+'export.csv')
                print "File converted. Attempting Google Analytics upload"

                parser = argparse.ArgumentParser(
                    formatter_class=argparse.RawDescriptionHelpFormatter,
                    parents=[tools.argparser])
                flags = parser.parse_args([])

                flow = OAuth2WebServerFlow(client_id=GOOGLE_CLIENT_ID,
                           client_secret=GOOGLE_CLIENT_SECRET,
                           scope=scope,
                           redirect_uri='urn:ietf:wg:oauth:2.0:oob')

                storage = file.Storage(credential_storage)
                credentials = storage.get()
                if credentials is None or credentials.invalid:
                    credentials = tools.run_flow(flow, storage, flags)

                http = credentials.authorize(http=httplib2.Http())

                service = build('analytics', 'v3', http=http)


                media = MediaFileUpload(FILE_DIRECTORY+'export.csv',
                          mimetype='application/octet-stream',
                          resumable=False)
                daily_upload = service.management().uploads().uploadData(
                    accountId=country['accountid'],
                    webPropertyId=country['propertyid'],
                    customDataSourceId=country['datasourceid'],
                    media_body=media).execute()
                print "Upload complete"
                break
            elif report_request_status.Status == 'Error':
                output_status_message(
                    "The request failed. Try requesting the report. \n" \
                    "later.\nIf the request continues to fail, contact support."
                )
                break
          if report_request_status is not None:
            if report_request_status.Status != 'Success' and report_request_status.Status != 'Error':
                output_status_message(
                    "The request is taking longer than expected. \n" \
                    "Save the report ID ({0}) and try again later.".format(report_request_id)
                )


    except WebFault as ex:
        output_webfault_errors(ex)
    except Exception as ex:
        output_status_message(ex)
